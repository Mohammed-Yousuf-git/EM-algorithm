{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOwqXE726JJKu0PaJAWj1tG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t6VZQZKZxZUx","executionInfo":{"status":"ok","timestamp":1733200209237,"user_tz":-330,"elapsed":523,"user":{"displayName":"Mohammed Yousuf","userId":"03590033271452149003"}},"outputId":"30153673-3ae4-4996-cc19-d48644be9af1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Converged at iteration 9.\n","Final means: [-0.05233444  5.07979589]\n","Final variances: [0.83075106 0.97249109]\n","Final weights: [0.49828183 0.50171817]\n"]}],"source":["import numpy as np\n","from scipy.stats import norm\n","\n","# Generate synthetic data for demonstration\n","np.random.seed(42)\n","data = np.concatenate([np.random.normal(0, 1, 200), np.random.normal(5, 1, 200)])\n","\n","# Initialize parameters\n","num_components = 2  # Number of Gaussian components\n","means = np.random.choice(data, num_components)\n","variances = np.random.random(num_components)\n","weights = np.ones(num_components) / num_components\n","\n","def e_step(data, means, variances, weights):\n","    \"\"\"E-step: calculate responsibilities.\"\"\"\n","    responsibilities = np.zeros((len(data), num_components))\n","    for k in range(num_components):\n","        responsibilities[:, k] = weights[k] * norm.pdf(data, means[k], np.sqrt(variances[k]))\n","    responsibilities /= responsibilities.sum(axis=1, keepdims=True)\n","    return responsibilities\n","\n","def m_step(data, responsibilities):\n","    \"\"\"M-step: update parameters.\"\"\"\n","    n_k = responsibilities.sum(axis=0)\n","    weights = n_k / len(data)\n","    means = (responsibilities.T @ data) / n_k\n","    # The following line has been modified\n","    variances = (np.sum(responsibilities * (data[:, np.newaxis] - means)**2, axis=0)) / n_k\n","    return weights, means, variances\n","\n","def log_likelihood(data, means, variances, weights):\n","    \"\"\"Compute the log likelihood of the data given the model parameters.\"\"\"\n","    likelihood = np.zeros(len(data))\n","    for k in range(num_components):\n","        likelihood += weights[k] * norm.pdf(data, means[k], np.sqrt(variances[k]))\n","    return np.sum(np.log(likelihood))\n","\n","# EM algorithm\n","max_iters = 100\n","tolerance = 1e-6\n","log_likelihoods = []\n","\n","for i in range(max_iters):\n","    # E-step\n","    responsibilities = e_step(data, means, variances, weights)\n","\n","    # M-step\n","    weights, means, variances = m_step(data, responsibilities)\n","\n","    # Compute log-likelihood\n","    log_likelihood_value = log_likelihood(data, means, variances, weights)\n","    log_likelihoods.append(log_likelihood_value)\n","\n","    # Check for convergence\n","    if i > 0 and abs(log_likelihoods[-1] - log_likelihoods[-2]) < tolerance:\n","        print(f\"Converged at iteration {i}.\")\n","        break\n","\n","# Results\n","print(\"Final means:\", means)\n","print(\"Final variances:\", variances)\n","print(\"Final weights:\", weights)"]},{"cell_type":"markdown","source":[],"metadata":{"id":"kgDKYx4VytSB"}}]}